# Ollama

I am paying for ChatGPT plus, but wanted to have a chatbot for Homeassistant that I could talk to. 

My computer does not have a graphics card, so this is just mildly useful for me. I tried out a few models, but running a `7B` model just doesnt make any sense. I have also tried smaller models like `gemma-2b:latest`, but that is unusable as an assistant model.

So, at the moment, I do not use this container much. There are also better implementations for home assistant at this point, so I might never actually use it